/**
 * autocannon/benchmark.ts
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * AUTOCANNON â€” Quick terminal benchmarks
 *
 * Autocannon is a Node.js-native tool â€” no extra install beyond npm.
 * Perfect for:
 *   - Quick "before vs after" comparison when you make a change
 *   - Testing a specific endpoint in isolation
 *   - Getting a rough req/s number fast
 *
 * Install:
 *   npm install autocannon
 *   npm install -D @types/autocannon
 *
 * Run:
 *   npx ts-node autocannon/benchmark.ts
 *   npx ts-node autocannon/benchmark.ts --endpoint users --connections 100
 */

import autocannon from "autocannon";

// â”€â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const BASE_URL    = process.env.BASE_URL    || "http://localhost:3000";
const CONNECTIONS = parseInt(process.env.CONNECTIONS || "50"); // concurrent connections
const DURATION    = parseInt(process.env.DURATION    || "30"); // seconds
const ENDPOINT    = process.env.ENDPOINT              || "all";

// â”€â”€â”€ Sample POST body â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function makeUserBody() {
  const rand = Math.random().toString(36).slice(2, 10);
  return JSON.stringify({
    name:  `Bench User ${rand}`,
    email: `bench.${rand}@autocannon.com`,
  });
}

// â”€â”€â”€ Run a single benchmark â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function runBenchmark(config: autocannon.Options): Promise<autocannon.Result> {
  return new Promise((resolve, reject) => {
    const instance = autocannon(config, (err, result) => {
      if (err) reject(err);
      else resolve(result);
    });

    // Print progress to console in real-time
    autocannon.track(instance, { renderProgressBar: true });
  });
}

// â”€â”€â”€ Print results in a readable table â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function printResults(label: string, result: autocannon.Result) {
  console.log(`\n${"â”€".repeat(60)}`);
  console.log(`  ğŸ“Š ${label}`);
  console.log(`${"â”€".repeat(60)}`);
  console.log(`  Connections:    ${result.connections}`);
  console.log(`  Duration:       ${result.duration}s`);
  console.log(`  Total requests: ${result.requests.total.toLocaleString()}`);
  console.log(`  Req/sec:        ${result.requests.mean.toFixed(0)} avg`);
  console.log(`                  ${result.requests.max.toFixed(0)} max`);
  console.log(`\n  Latency:`);
  console.log(`    p50  = ${result.latency.p50}ms`);
  console.log(`    p75  = ${result.latency.p75}ms`);
  console.log(`    p90  = ${result.latency.p90}ms`);
  console.log(`    p99  = ${result.latency.p99}ms`);
  console.log(`    max  = ${result.latency.max}ms`);
  console.log(`\n  Errors: ${result.errors} (${((result.errors / result.requests.total) * 100).toFixed(2)}%)`);
  console.log(`  Timeouts: ${result.timeouts}`);
  console.log(`  Throughput: ${(result.throughput.mean / 1024).toFixed(1)} KB/s avg`);
  console.log(`${"â”€".repeat(60)}`);

  // Simple pass/fail
  const p99ok   = result.latency.p99 < 500;
  const errorsOk = result.errors === 0;
  const rpsOk   = result.requests.mean > 100;

  console.log(`\n  ${p99ok    ? "âœ…" : "âŒ"} p99 < 500ms   (actual: ${result.latency.p99}ms)`);
  console.log(`  ${errorsOk  ? "âœ…" : "âŒ"} Zero errors    (actual: ${result.errors})`);
  console.log(`  ${rpsOk     ? "âœ…" : "âŒ"} > 100 req/s    (actual: ${result.requests.mean.toFixed(0)})`);
}

// â”€â”€â”€ Benchmarks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function main() {
  console.log(`\nğŸ”¥ Autocannon Benchmark`);
  console.log(`   Target:      ${BASE_URL}`);
  console.log(`   Connections: ${CONNECTIONS} concurrent`);
  console.log(`   Duration:    ${DURATION}s per test\n`);

  const common = {
    url: BASE_URL,
    connections: CONNECTIONS,
    duration: DURATION,
    pipelining: 1,       // HTTP pipelining â€” 1 = normal, >1 = aggressive
    timeout: 10,         // request timeout in seconds
  };

  // â”€â”€ 1. GET /api/users (list) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  if (ENDPOINT === "all" || ENDPOINT === "list") {
    console.log("\nğŸ§ª Test 1: GET /api/users (list endpoint)");
    const listResult = await runBenchmark({
      ...common,
      url: `${BASE_URL}/api/users?limit=20`,
    });
    printResults("GET /api/users?limit=20", listResult);
  }

  // â”€â”€ 2. GET /api/users/:id (single) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  if (ENDPOINT === "all" || ENDPOINT === "users") {
    console.log("\nğŸ§ª Test 2: GET /api/users/1 (single user)");
    const singleResult = await runBenchmark({
      ...common,
      url: `${BASE_URL}/api/users/1`,
    });
    printResults("GET /api/users/1", singleResult);
  }

  // â”€â”€ 3. POST /api/users (create) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // For POST, we need to vary the body to avoid duplicate email errors.
  // autocannon supports a "requests" array that cycles through bodies.
  if (ENDPOINT === "all" || ENDPOINT === "post") {
    console.log("\nğŸ§ª Test 3: POST /api/users (create user)");

    // Pre-generate 1000 unique bodies to cycle through
    const bodies = Array.from({ length: 1000 }, () => makeUserBody());
    let bodyIndex = 0;

    const postResult = await runBenchmark({
      ...common,
      method: "POST",
      // autocannon "requests" lets you cycle through different request configs
      requests: bodies.map((body) => ({
        method: "POST" as const,
        path: "/api/users",
        headers: { "content-type": "application/json" },
        body,
      })),
    });
    printResults("POST /api/users", postResult);
  }

  // â”€â”€ 4. Mixed workload â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  if (ENDPOINT === "all" || ENDPOINT === "mixed") {
    console.log("\nğŸ§ª Test 4: Mixed workload (80% GET, 20% POST)");

    // Build 1000 requests: 800 GETs + 200 POSTs, shuffled
    const requests: autocannon.Request[] = [];

    for (let i = 0; i < 800; i++) {
      const id = Math.ceil(Math.random() * 10000);
      requests.push({ method: "GET", path: `/api/users/${id}` });
    }
    for (let i = 0; i < 200; i++) {
      requests.push({
        method: "POST",
        path: "/api/users",
        headers: { "content-type": "application/json" },
        body: makeUserBody(),
      });
    }

    // Shuffle the array
    for (let i = requests.length - 1; i > 0; i--) {
      const j = Math.floor(Math.random() * (i + 1));
      [requests[i], requests[j]] = [requests[j], requests[i]];
    }

    const mixedResult = await runBenchmark({
      ...common,
      url: BASE_URL,
      requests,
    });
    printResults("Mixed workload (80/20 GET/POST)", mixedResult);
  }

  console.log("\nâœ… Benchmarks complete!\n");
}

main().catch(console.error);

/*
 * â”€â”€â”€ EXAMPLE OUTPUT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 *
 * Running 30s test @ http://localhost:3000/api/users?limit=20
 * 50 connections
 *
 * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”
 * â”‚ Stat        â”‚ 2.5% â”‚ 50%  â”‚ 97.5% â”‚ 99%   â”‚ Avg      â”‚ Stdev   â”‚ Max   â”‚
 * â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
 * â”‚ Latency     â”‚ 3ms  â”‚ 5ms  â”‚ 12ms  â”‚ 18ms  â”‚ 5.8ms    â”‚ 2.9ms   â”‚ 120ms â”‚
 * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
 *
 * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 * â”‚ Stat       â”‚  1%     â”‚ 2.5%    â”‚ 50%     â”‚ 97.5%
 * â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
 * â”‚ Req/Sec    â”‚ 6820    â”‚ 7100    â”‚ 8200    â”‚ 8500
 * â”‚ Bytes/Sec  â”‚ 2.1 MB  â”‚ 2.2 MB  â”‚ 2.5 MB  â”‚ 2.6 MB
 * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 *
 * Req/Bytes counts sampled once per second.
 * 246k requests in 30.1s, 74.9 MB read
 *
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 *  ğŸ“Š GET /api/users?limit=20
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 *  Req/sec:       8200 avg
 *  Latency p50:   5ms
 *  Latency p99:   18ms
 *  Errors:        0 (0.00%)
 *
 *  âœ… p99 < 500ms   (actual: 18ms)
 *  âœ… Zero errors   (actual: 0)
 *  âœ… > 100 req/s   (actual: 8200)
 */