/**
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 *  TIER 2 â€” 10,000 requests/second
 *  Stack: Cluster + TypeScript + Express + pg + compression
 *  Target: Growing apps, moderate traffic
 *  Hardware: 1 server, 8 CPU cores, 8GB RAM
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 *
 *  NEW vs TIER 1:
 *  âœ… Node.js Cluster â€” use ALL CPU cores (8x throughput)
 *  âœ… Compression â€” GZIP responses (70-80% less bandwidth)
 *  âœ… Helmet â€” security headers
 *  âœ… Rate limiting â€” protect from abuse
 *  âœ… Structured logging with Pino (async, non-blocking)
 *  âœ… Bigger connection pool (20 per worker)
 *  âœ… Graceful shutdown
 */

import cluster from "cluster";
import os from "os";

const NUM_CPUS = os.cpus().length; // 8 on a typical 8-core server

if (cluster.isPrimary) {
  console.log(`[Primary] PID ${process.pid} â€” forking ${NUM_CPUS} workers`);

  for (let i = 0; i < NUM_CPUS; i++) {
    cluster.fork();
  }

  // Auto-restart dead workers â€” zero downtime on crashes
  cluster.on("exit", (worker, code, signal) => {
    console.warn(`[Primary] Worker ${worker.process.pid} died (${signal || code}) â€” restarting`);
    cluster.fork();
  });

} else {
  // Each worker independently imports and runs the Express app
  console.log(`[Worker] PID ${process.pid} booting`);
  require("./app");
}


/**
 * â”€â”€â”€ TIER 2 SUMMARY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 *
 *  âœ… What's new:
 *     - Cluster: 8 workers Ã— ~1.5k req/s = ~10k req/s total
 *     - Parallel DB queries with Promise.all
 *     - Pino structured logging (async, 5x faster than console)
 *     - Compression, Helmet, Rate limiting
 *     - Graceful shutdown
 *
 *  âŒ Still missing (not needed yet):
 *     - Redis caching
 *     - Load balancer (still one server)
 *     - Read replicas
 *
 *  ğŸ“Š Benchmark targets:
 *     - Latency p99: < 30ms
 *     - Throughput:  10,000 req/s
 *     - DB connections: 160 (20 Ã— 8 workers)
 *     - Servers needed: 1 (8-core)
 *
 *  ğŸ”§ postgresql.conf changes needed:
 *     max_connections = 200
 *     shared_buffers = 2GB
 */
